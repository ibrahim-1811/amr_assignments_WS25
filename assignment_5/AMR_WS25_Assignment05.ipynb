{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8dadca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbassignment": {
     "type": "header"
    },
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61c7e7acf8c5bdb945139d60a161a008",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "|        |        |        |\n",
    "|--------|--------|--------|\n",
    "![H-BRS](logos/h-brs.png) | ![A2S](logos/a2s.png) | ![b-it](logos/b-it.png) |\n",
    "\n",
    "# Autonomous Mobile Robots\n",
    "\n",
    "# AMR Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9220f1d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44f7ff21f9522a124e34b5d501542440",
     "grade": false,
     "grade_id": "preamble",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General information\n",
    "\n",
    "* Please do not add or delete any cells. Answers belong into the already provided cells (below the question).\n",
    "* If a function is given (either as a signature or a full function), you should not change the name, arguments, or return value of the function.\n",
    "* If you encounter empty cells underneath the answer that can not be edited, please ignore them; they are for testing purposes.\n",
    "* Please note that variables declared in the notebook cells have global scope. To make sure your assignment works correctly as a whole, please restart the kernel and run all cells before submitting (e.g. via *Kernel -> Restart & Run All*).\n",
    "* Code cells where you are supposed to give your answer often include the line  ```raise NotImplementedError```. This makes it easier to automatically grade answers. Once you fill out a function, please delete this line.\n",
    "\n",
    "### Submission\n",
    "\n",
    "Please make sure to write all your team members 2s IDs in the cell below before submission. Please submit your notebook via the JupyterHub web interface (in the main view -> Assignments -> Submit). If it is a group assignment, please make only one submission per group (for easier bookkeeping, it is best if this is always the same team member).\n",
    "\n",
    "### Questions about the assignment\n",
    "\n",
    "If you have questions about the assignment, you are encouraged to post them in the LEA forum. Proactive discussions lead to better understanding. Let's keep the forum active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c9eb0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c214edb5291a96d02194fb59cf728f04",
     "grade": true,
     "grade_id": "team_members",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## Team members (2s IDs):\n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "* Mmemon2s\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bf078",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81b5f5f4a727d76331cdc6721bdddf11",
     "grade": false,
     "grade_id": "Landmark_based_localisation_Kalman_A_Header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Landmark-based Localisation using Kalman Filter (100 points)\n",
    "\n",
    "In this assignment, we will use a Kalman filter for localisation in an environment based on the measurement of landmark locations. As you already know, sensor readings are affected by noise, making it difficult to achieve accurate measurement of the physical quantity under consideration. The Kalman filter, which belongs to the family of Bayes filter algorithms, can be used for minimising the error in the estimation. The belief of the state (in this case, it is the **pose of the robot** with respect to the **map frame**) is represented as a Gaussian distribution. The objective is to estimate the mean $\\mu$ and covariance matrix $\\Sigma$ for the physical quantity under consideration at every time instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd2aeb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5d2fabf84c59ec19bab11bcd4ed5d76",
     "grade": false,
     "grade_id": "Landmark_based_localisation_Kalman_A_Description0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this assignment, the Robile is placed in a simulation environment in Gazebo, where several RFID tags are positioned on the ground. Now, suppose that a virtual RFID detector is mounted on the robot, sharing the *same frame* and *field of view* as the LiDAR. In the real world, the robot's real pose almost never matches with its ideal motion model due to different sources of noise, such as from the encoder readings, unstructured environment interaction, as well as other noisy perception data.\n",
    "\n",
    "In this assignment, we will explore how the Kalman filter can be employed to improve the estimation of the robot's pose in this setup. Below is the simulation environment where the RFID tags are highlighted.\n",
    "\n",
    "![robile_localisation_kalman](img/robile_localisation_kalman.png)\n",
    "\n",
    "The positions of the RFID tags as $(x,y)$ coordinates in the `odom` frame with tag names are as follows:  \n",
    "- A: $(1.0, 1.0)$\n",
    "- B: $(6.0, 1.0)$\n",
    "- C: $(3.0, -1.0)$\n",
    "- D: $(1.0, -3.0)$\n",
    "- E: $(4.0, -4.0)$\n",
    "\n",
    "### Motion noise consideration\n",
    "\n",
    "When the robot is moving in the environment, the noise in the data published onto the `/odom` topic is negligible in the simulation. To simulate the real-world noise, for every message on the `/odom` topic, some noise is introduced manually in the associated *robile_rfid_tag_finder.py* script, and the variable `real_base_link_pose` is updated accordingly. Here, the data on the `/odom` topic, and consequently the visualization of the robot model in RVIZ, can be considered as an ideal motion model, which is the motion estimate without noise; the data on `real_base_link_pose` is then the actual pose of the robot's base (`real_base_link` frame) with respect to which the RFID tags are measured, and which are available on the `/rfid_tag_poses` topic. The `real_base_link_pose` topic thus represents the actual pose of the robot, which deviates from `/odom` due to uncertain interaction with the environment.\n",
    "\n",
    "Your goal is to read from the `odom` topic and, along with the measured RFID tag positions, estimate the posterior belief of the robot's pose and the variance associated with it. This estimated pose, which should be published to the `estimated_base_link_pose` topic, should eventually converge to the pose represented on `real_laser_link_pose`.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The pose of the robot with respect to the odom frame, published on the `/odom` topic represents ideal motion without noise.\n",
    "- Since it is challenging to mathematically represent or model all physical interactions with the environment, in reality, the robot deviates from the ideal motion and its pose estimation is affected by noise in the sensor data and an incomplete model of the interaction with the environment. The actual robot pose is considered to be the `real_base_link` frame.\n",
    "- The measurement model is the pose estimate using the detected RFID tags on the `/rfid_tag_poses` topic, which is represented by a custom message of type ``PoseLabelledArray``. These tags are measured with respect to the `real_base_link` frame.\n",
    "- Note that the `real_base_link` frame is only used to visualise the actual robot pose; thus, only the data on `/odom` and `/rfid_tag_poses` topics should be used to determine robot's posterior pose `estimated_base_link_pose`.\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The initial `real_base_link` frame is considered to be overlapping with the `odom` frame.\n",
    "- To determine the robot's pose by the measurement of RFID tag positions, at least two tags needs to be perceived. The problem could be made simpler by considering the pose estimated using these RFID positions as measurement data rather than the measured RFID positions themselves.\n",
    "- The initial state, i.e., the `estimated_base_link_pose` pose at the start of simulation is considered the same as the pose of the `odom` frame, namely `estimated_base_link_pose` can be considered as initially known with zero or constant uncertainty. Optionally, it can be updated using the `2D Pose Estimate` widget in RVIZ, in which case the mean and variance of the estimate should be reset.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Upload the modified `robile_navigation` package with your submission, and also paste your Kalman filter implementation in the cell below. Before starting your implementation please follow these steps:\n",
    "\n",
    "- Modify the simulation launch file to load the `closed_walls.world` environment from the `robile_gazebo` package\n",
    "- Implement pose estimation using a Kalman filter in the `robile_localisation_kalman.py` script from the `robile_navigation` repository\n",
    "- Use the launch file `landmark_based_localisation.launch.py` under `robile_navigation` and modify it accordingly to launch your implementation\n",
    "- Please feel free to modify any of the scripts according to your needs\n",
    "\n",
    "### Potentially useful references\n",
    "\n",
    "- Section 5.6.8.5 in the \"Introduction to Autonomous Mobile Robots\" book. It doesn't have the same setup, but is still useful\n",
    "- https://www.alanzucconi.com/2022/07/24/kalman-gain/\n",
    "- http://bilgin.esme.org/BitsAndBytes/KalmanFilterforDummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b888c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4eed1c52759367f9e9aed29717c791e",
     "grade": true,
     "grade_id": "Landmark_based_localisation_Kalman_A",
     "locked": false,
     "points": 90,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Paste your code from robile_localisation_kalman.py in this cell\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from geometry_msgs.msg import PoseStamped\n",
    "from robile_interfaces.msg import PositionLabelledArray\n",
    "from nav_msgs.msg import Odometry\n",
    "import numpy as np\n",
    "import tf2_ros\n",
    "from tf_transformations import euler_from_quaternion, quaternion_from_euler\n",
    "import time\n",
    "\n",
    "class LocalisationUsingKalmanFilter(Node):\n",
    "    \"\"\"\n",
    "    Landmark based localisation using Kalman Filter\n",
    "    This is a partially structured class for AMR assignment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('localisation_using_kalman_filter')\n",
    "\n",
    "        # declaring and getting parameters from yaml file\n",
    "        self.declare_parameters(\n",
    "            namespace='',\n",
    "            parameters=[\n",
    "                ('map_frame', 'map'),\n",
    "                ('odom_frame', 'odom'),                \n",
    "                ('laser_link_frame', 'base_laser_front_link'),\n",
    "                ('real_base_link_frame', 'real_base_link'),\n",
    "                ('scan_topic', 'scan'),\n",
    "                ('odom_topic', 'odom'),\n",
    "                ('rfid_tag_poses_topic', 'rfid_tag_poses'),\n",
    "                ('initial_pose_topic', 'initialpose'),\n",
    "                ('real_base_link_pose_topic', 'real_base_link_pose'),\n",
    "                ('estimated_base_link_pose_topic', 'estimated_base_link_pose'),\n",
    "                ('minimum_travel_distance', 0.1),\n",
    "                ('minimum_travel_heading', 0.1),\n",
    "                ('rfid_tags.A', [0.,0.]),\n",
    "                ('rfid_tags.B', [0.,0.]),\n",
    "                ('rfid_tags.C', [0.,0.]),\n",
    "                ('rfid_tags.D', [0.,0.]),\n",
    "                ('rfid_tags.E', [0.,0.]),                        \n",
    "            ])\n",
    "\n",
    "        self.map_frame = self.get_parameter('map_frame').get_parameter_value().string_value\n",
    "        self.odom_frame = self.get_parameter('odom_frame').get_parameter_value().string_value\n",
    "        self.laser_link_frame = self.get_parameter('laser_link_frame').get_parameter_value().string_value\n",
    "        self.real_base_link_frame = self.get_parameter('real_base_link_frame').get_parameter_value().string_value\n",
    "        self.scan_topic = self.get_parameter('scan_topic').get_parameter_value().string_value\n",
    "        self.odom_topic = self.get_parameter('odom_topic').get_parameter_value().string_value\n",
    "        self.rfid_tag_poses_topic = self.get_parameter('rfid_tag_poses_topic').get_parameter_value().string_value\n",
    "        self.initial_pose_topic = self.get_parameter('initial_pose_topic').get_parameter_value().string_value\n",
    "        self.real_base_link_pose_topic = self.get_parameter('real_base_link_pose_topic').get_parameter_value().string_value\n",
    "        self.estimated_base_link_pose_topic = self.get_parameter('estimated_base_link_pose_topic').get_parameter_value().string_value\n",
    "        self.minimum_travel_distance = self.get_parameter('minimum_travel_distance').get_parameter_value().double_value\n",
    "        self.minimum_travel_heading = self.get_parameter('minimum_travel_heading').get_parameter_value().double_value\n",
    "        self.rfid_tags_A = self.get_parameter('rfid_tags.A').get_parameter_value().double_array_value\n",
    "        self.rfid_tags_B = self.get_parameter('rfid_tags.B').get_parameter_value().double_array_value\n",
    "        self.rfid_tags_C = self.get_parameter('rfid_tags.C').get_parameter_value().double_array_value\n",
    "        self.rfid_tags_D = self.get_parameter('rfid_tags.D').get_parameter_value().double_array_value\n",
    "        self.rfid_tags_E = self.get_parameter('rfid_tags.E').get_parameter_value().double_array_value\n",
    "        self.lastOdometry = None\n",
    "\n",
    "        # setting up laser scan and rfid tag subscribers\n",
    "        self.rfid_tag_subscriber = self.create_subscription(PositionLabelledArray, self.rfid_tag_poses_topic, self.rfid_callback, 10)\n",
    "        self.real_laser_link_subscriber = self.create_subscription(PoseStamped, self.real_base_link_pose_topic, self.real_base_link_pose_callback, 10)        \n",
    "        self.odom_subscriber = self.create_subscription(Odometry, self.odom_topic, self.updateBelief, 10)\n",
    "        self.estimated_robot_pose_publisher = self.create_publisher(PoseStamped, self.estimated_base_link_pose_topic, 10)\n",
    "        \n",
    "        # setting up tf2 listener\n",
    "        self.tf_buffer = tf2_ros.Buffer()\n",
    "        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)\n",
    "\n",
    "        self.state = np.array([0.,0.,0.]) # This is x0 which contains x,y,theta\n",
    "        self.cov = np.eye(3,3)*1e-8\n",
    "        self.mutexUpdate = False\n",
    "\n",
    "        # In homogeneous coordinates\n",
    "        self.odomRFID = {\n",
    "            \"A\": np.array([1.0, 1.0, 1.0]),\n",
    "            \"B\": np.array([6.0, 1.0, 1.0]),\n",
    "            \"C\": np.array([3.0, -1.0, 1.0]),\n",
    "            \"D\": np.array([1.0, -3.0, 1.0]),\n",
    "            \"E\": np.array([4.0, -4.0, 1.0])\n",
    "        }\n",
    "\n",
    "        self.tf_buffer = tf2_ros.Buffer()\n",
    "        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)\n",
    "\n",
    "    def getTransformation(self):\n",
    "        x,y,theta = self.state\n",
    "        s = np.sin(theta)\n",
    "        c = np.cos(theta)\n",
    "        return np.array([\n",
    "            [c,-s,x],\n",
    "            [s,c,y],\n",
    "            [0,0,1],\n",
    "        ])\n",
    "    \n",
    "    def quatToAngle(self, quat):\n",
    "        return euler_from_quaternion([quat.x, quat.y, quat.z, quat.w])[2]\n",
    "    \n",
    "    def extractSubCov(self, cov):\n",
    "        return cov.reshape(6,6)[(0,1,5), :][:, (0,1,5)]\n",
    "    \n",
    "    def getBeliefRFIDError(self, detectedRFID):\n",
    "        tranformation = self.getTransformation()\n",
    "\n",
    "        idToIdx = {\"A\":0,\"B\":1,\"C\":2,\"D\":3,\"E\":4}\n",
    "        beliefRFIDError = np.zeros((6,1))\n",
    "        for el in detectedRFID.positions:\n",
    "            idx = idToIdx[el.name]\n",
    "            transformedPoint = np.dot(tranformation,self.odomRFID[el.name].T).T\n",
    "            #6x1\n",
    "            beliefRFIDError[idx] = np.sqrt((el.position.x - transformedPoint[0])**2 + (el.position.y - transformedPoint[1])**2)\n",
    "\n",
    "        return beliefRFIDError\n",
    "\n",
    "    def computeKalmanGain(self):\n",
    "        H = np.ones((6,3))\n",
    "        R = np.eye(6,6) * 0.01\n",
    "        t1 = np.matmul(self.cov, H.T)\n",
    "        t2 = np.matmul(H,np.matmul(self.cov, H.T))+R\n",
    "        K = np.matmul(t1, np.linalg.inv(t2))\n",
    "        return K \n",
    "\n",
    "    def rfid_callback(self, msg: PositionLabelledArray):\n",
    "        \"\"\"\n",
    "        Based on the detected RFID tags, performing measurement update\n",
    "        \"\"\"        \n",
    "        if not self.mutexUpdate:\n",
    "            return\n",
    "        \n",
    "        self.mutexUpdate = False\n",
    "        poseEstimation = PoseStamped()\n",
    "\n",
    "        K = self.computeKalmanGain()\n",
    "\n",
    "        be = self.getBeliefRFIDError(msg)\n",
    "\n",
    "        self.state += np.dot(K,be)[:,0]\n",
    "\n",
    "        self.cov = np.dot((np.eye(3,3) - np.dot(K, np.ones((6,3)))), self.cov)\n",
    "\n",
    "        poseEstimation.header.stamp = self.get_clock().now().to_msg()\n",
    "        poseEstimation.header.frame_id = self.map_frame\n",
    "        poseEstimation.pose.position.x = self.state[0]\n",
    "        poseEstimation.pose.position.y = self.state[1]\n",
    "        poseEstimation.pose.position.z = 0.\n",
    "        quat = quaternion_from_euler(0,0,self.state[2])\n",
    "        poseEstimation.pose.orientation.x = quat[0]\n",
    "        poseEstimation.pose.orientation.y = quat[1]\n",
    "        poseEstimation.pose.orientation.z = quat[2]\n",
    "        poseEstimation.pose.orientation.w = quat[3]\n",
    "\n",
    "        print(\"LINK POSE REAL\", self.real_laser_link_pose)\n",
    "        print(\"STATE\", self.state)\n",
    "\n",
    "        self.estimated_robot_pose_publisher.publish(poseEstimation)\n",
    "\n",
    "    def real_base_link_pose_callback(self, msg):\n",
    "        \"\"\"\n",
    "        Updating the base_link pose based on the update in robile_rfid_tag_finder.py\n",
    "        \"\"\"\n",
    "        yaw = euler_from_quaternion([msg.pose.orientation.x, msg.pose.orientation.y, msg.pose.orientation.z, msg.pose.orientation.w])[2]\n",
    "        self.real_laser_link_pose = [msg.pose.position.x, msg.pose.position.y, yaw]\n",
    "\n",
    "    def updateBelief(self, msg:Odometry):\n",
    "        if not self.lastOdometry:\n",
    "            self.lastOdometry = msg\n",
    "            return \n",
    "\n",
    "        linearOfft = np.array([msg.pose.pose.position.x - self.lastOdometry.pose.pose.position.x, \n",
    "                               msg.pose.pose.position.y - self.lastOdometry.pose.pose.position.y ])\n",
    "        angularOfft = self.quatToAngle(msg.pose.pose.orientation) - self.quatToAngle(self.lastOdometry.pose.pose.orientation)\n",
    "\n",
    "        if np.linalg.norm(linearOfft) < self.minimum_travel_distance and abs(angularOfft) < self.minimum_travel_heading:\n",
    "            return\n",
    "        \n",
    "        covOfft = self.extractSubCov(msg.pose.covariance) - self.extractSubCov(self.lastOdometry.pose.covariance)\n",
    "\n",
    "        self.state += np.append(linearOfft, angularOfft)\n",
    "        self.cov += covOfft\n",
    "        self.lastOdometry = msg\n",
    "\n",
    "        self.mutexUpdate = True\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "\n",
    "    try:\n",
    "        localisation_using_kalman_filter = LocalisationUsingKalmanFilter()\n",
    "        rclpy.spin(localisation_using_kalman_filter)\n",
    "\n",
    "    finally:\n",
    "        localisation_using_kalman_filter.destroy_node()\n",
    "        rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f985e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "604f8d1c039395c4535afec3fd6a1db5",
     "grade": false,
     "grade_id": "cell-41799b9311561a40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, comment on your observations while evaluating your implementation in the cell below, and include relevant screenshots to verify your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7286110",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd39c3ea6aa51c21896d72bfd78b47bf",
     "grade": true,
     "grade_id": "cell-fd82eec8922f9e03",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
